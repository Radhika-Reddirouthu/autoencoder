{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from math import ceil\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing import image \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the path of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() \n",
    "train_path = PATH+'/dataset/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below function returns the label/file name of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(name):\n",
    "    if name:\n",
    "        img_name = name.split(\"/dataset/\")\n",
    "        img_name = img_name[1].split(\".jpg\")\n",
    "        return img_name[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding labels of all the images in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './dataset/*.jpg'\n",
    "images = glob.glob(img_path)\n",
    "labels = []\n",
    "k=0\n",
    "for img in images:\n",
    "    # get the image unique id and set it as the label\n",
    "    label_id = get_label(img)\n",
    "    labels.append(label_id)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and test dataset\n",
    "80% of the data is used for training and 20% of the data is used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of images in train set: 3790\n",
      "no.of images in test set: 948\n"
     ]
    }
   ],
   "source": [
    "length=int((len(labels)*80/100))\n",
    "train_sample = images[0:length]\n",
    "train_label= labels[0:length]\n",
    "test_sample=images[length:len(labels)]\n",
    "test_label=labels[length:len(labels)]\n",
    "print(\"no.of images in train set:\", len(train_sample))\n",
    "print(\"no.of images in test set:\", len(test_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retreive similar images  from dataset as that of the test_image:\n",
    "the below function takes as input the trained codes, test image and label. Test code for the test image is predicted and the distance between the test code and each trained code is computed and based the distance, indexes of the top \"N\" closed images are returned.\n",
    "\n",
    "trained_codes: output of the encoder layer for all the training images\n",
    "\n",
    "test_codes: output of the encoder image for the test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_closest_images(trained_codes, test_element, test_label, n_samples):\n",
    "    # reshape the trained codes\n",
    "    trained_codes = trained_codes.reshape(trained_codes.shape[0], trained_codes.shape[1]*trained_codes.shape[2]*trained_codes.shape[3])\n",
    "    \n",
    "    # predict the encoder layer codes for the test image\n",
    "    test_codes = encoder.predict(np.array([test_element]))\n",
    "    # reshape the tested codes of the test image\n",
    "    test_codes = test_codes.reshape(test_codes.shape[1]*test_codes.shape[2]*test_codes.shape[3])\n",
    "    \n",
    "    # initialize the distance list\n",
    "    distances = []\n",
    "\n",
    "    for code in trained_codes:\n",
    "        # for each code of the training images, compute the Euclidean distance between the train image and test image\n",
    "        distance = np.linalg.norm(code - test_codes)\n",
    "        distances.append(distance)# append to the distance list\n",
    "            \n",
    "\n",
    "    nb_elements = trained_codes.shape[0] # get the total number of images in the training set\n",
    "    distances = np.array(distances) # convert the distance list to a numpy array\n",
    "    trained_code_index = np.arange(nb_elements) # creae an index list from 0 - nb_elements\n",
    "    \n",
    "    # create a numpy stack with the distances, index_list\n",
    "    distance_with_index = np.stack((distances, trained_code_index), axis=-1)\n",
    "    sorted_distance_with_index = distance_with_index[distance_with_index[:,0].argsort()] # sort the stack\n",
    "    sorted_distances = sorted_distance_with_index[:, 0].astype('float32') # change the datatype\n",
    "    sorted_indexes = sorted_distance_with_index[:, 1]\n",
    "    kept_indexes = sorted_indexes[:n_samples] # Get the first N indexes of the sorted_indexes list\n",
    "\n",
    "    return kept_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize width, height, train and test batch size as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224 #Given images are of 512*512 shape\n",
    "height = 224\n",
    "train_batch_size = 20\n",
    "test_batch_size = 10\n",
    "train_size=len(train_sample)\n",
    "test_size=len(test_sample)\n",
    "# define the batch lists with the batch sizes\n",
    "train_list = list(range(int(ceil(float(train_size) / train_batch_size))))\n",
    "test_list = list(range(int(ceil(float(test_size) / test_batch_size))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loding the model that is saved after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder.h5')\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder').output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the below cell which predicts the output of the encoder layer for all the training images and stored in the variable trained_codes\n",
    "##### Note: skip below 2 cells if the trained_codes are already predicted once and saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_codes = np.array([], dtype='float32').reshape(0,28,28, 8) # initialize the training codes\n",
    "\n",
    "# predict the encoder layer features for the training dataset\n",
    "for n, i in enumerate(train_list):\n",
    "    i_s = i * train_batch_size\n",
    "    i_e = min([(i + 1) * train_batch_size, train_size])\n",
    "    train_images=[]\n",
    "    train_labels=[]\n",
    "    for j in range(i_s,i_e):\n",
    "        img_addr = train_sample[j]\n",
    "        img = cv2.imread(img_addr)\n",
    "        img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "        img_lbl = get_label(img_addr) # get the unique ID\n",
    "        train_images.append(img) # append the images\n",
    "        img_lbl = np.array([img_lbl]) \n",
    "        train_labels.append(img_lbl) # append the labels\n",
    "    x_train=np.array(train_images, dtype=np.float32)/255.\n",
    "    y_train = train_labels\n",
    "    print('predicting for ', i_s, ' to ', i_e, '\\n')\n",
    "    predicted_codes = encoder.predict(x_train)\n",
    "    trained_codes = np.concatenate((trained_codes, predicted_codes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the trained_codes for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train_codes.sav\"\n",
    "pickle.dump(trained_codes, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the below cell to load the trained_codes if they are already predicted and saved by running above 2 cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_codes = pickle.load(open('train_codes.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below function is used to plot the images in a grid format (sub plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(result):\n",
    "    w=20\n",
    "    h=20\n",
    "    fig=plt.figure(figsize=(50, 50))\n",
    "    columns = 3\n",
    "    rows = ceil(len(result)/columns)\n",
    "    for i in range(1, columns*rows +1):\n",
    "        if i==len(result)+1:\n",
    "            break\n",
    "        temp=str(result[i-1])+\".jpg\"\n",
    "        img_path = train_path+temp \n",
    "        x = image.load_img(img_path)\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        #plt.axis(\"off\")\n",
    "        plt.imshow(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model:\n",
    "test_model reads images from test sample and normalize it.\n",
    "Further it send trained codes(output of encoder layer fo all training images),test image, test label to retrieve_closest_images function which predicts and returns indexes of top N closest images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_size,test_sample,width,height):\n",
    "    test_images=[]\n",
    "    test_labels=[]\n",
    "    N=10\n",
    "    # enumerate over the test images\n",
    "    for j in range(test_size):\n",
    "        img_addr = test_sample[j]\n",
    "        img = cv2.imread(img_addr)\n",
    "        #when cv2 read the image it it converted to BGR image so to display the original image again converting back to RGB\n",
    "        img_display = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img_display)    \n",
    "        img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "        img_lbl = get_label(img_addr) # get the unique ID\n",
    "        test_images.append(img) # append the images\n",
    "        img_lbl = np.array([img_lbl]) \n",
    "        test_labels.append(img_lbl) # append the labels\n",
    "        x_test=np.array(img, dtype=np.float32)/255.\n",
    "        y_test = test_labels\n",
    "        similar_indexes = retrieve_closest_images(trained_codes, x_test, y_test,N) # retrieve the indexes closest images for the give test image\n",
    "        similar_indexes = similar_indexes.astype('int')\n",
    "        temp= len(similar_indexes)/2\n",
    "        result=[]\n",
    "        for i in similar_indexes:\n",
    "            result.append(labels[i])\n",
    "        plot_images(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(test_size,test_sample,width,height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing your own image\n",
    "User need to give either the path of the image or the label of the image as input and the below function predicts top N closest images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_image(random,train_path,width,height,labels,N):\n",
    "    if len(random)<=4:\n",
    "        img_path = train_path+random+\".jpg\" \n",
    "    else:\n",
    "        img_path=random\n",
    "    #img_addr = image.load_img(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    #when cv2 read the image it it converted to BGR image so to display the original image again converting back to RGB\n",
    "    img_display = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    #plt.axis(\"off\")\n",
    "    plt.imshow(img_display)   \n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_CUBIC)\n",
    "    img_lbl = get_label(img_path) # get the unique ID\n",
    "    x_test=np.array(img, dtype=np.float32)/255.\n",
    "    y_test = img_lbl\n",
    "    similar_indexes = retrieve_closest_images(trained_codes, x_test, y_test,N) # retrieve the indexes closest images for the give test image\n",
    "    similar_indexes = similar_indexes.astype('int')\n",
    "    temp= len(similar_indexes)/2\n",
    "    result=[]\n",
    "    for i in similar_indexes:\n",
    "        result.append(labels[i])\n",
    "    plot_images(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "random=input(\"enter a number from 1 to 100 or give the path of the image:\")\n",
    "test_your_image(random,train_path,width,height,labels,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
